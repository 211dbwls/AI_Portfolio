{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNVOBvXZXUtAArnw9j02WJ3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **차량 공유업체의 차량 파손 여부 분류하기**"],"metadata":{"id":"nvebqjdlxwyW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"xral9px9wh0U"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import VGG16\n","\n","dataset_path  = '/content/drive/MyDrive/Datasets/'"],"metadata":{"id":"bjDKUPicyYo0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 1.모델링 I\n","* **세부요구사항**\n","    * 모델링을 위한 데이터 구조 만들기\n","        * x : 이미지를 array로 변환합니다.\n","        * y : 이미지 갯수만큼 normal - 0, abnormal - 1 로 array를 만듭니다.\n","    * 모델을 최소 3개 이상 만들고 성능을 비교합니다.\n","        * 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","        * 전처리 과정에서 생성한 Validation set을 적절하게 사용하세요.\n","        * Early Stopping을 반드시 사용하세요.\n","            * 최적의 가중치를 모델에 적용하세요."],"metadata":{"id":"cBSy7qqqyG7L"}},{"cell_type":"markdown","source":["### (1) X : image to array\n","- **세부요구사항**\n","    * 모델링을 위해서는 np.array 형태로 데이터셋을 만들어야 합니다.\n","    * Training set / Validation set / Test set의 X는 이미지 형태로 되어있습니다. \n","    * 이미지 파일을 불러와 train, valid, test 각각 array 형태로 변환해 봅시다.\n","        * 각 폴더로 부터 이미지 목록을 만들고\n","        * 이미지 한장씩 적절한 크기로 로딩하여 (keras.utils.load_img)\n","            * 이미지가 너무 크면 학습시간이 많이 걸리고, 메모리 부족현상이 발생될 수 있습니다.\n","            * 이미지 크기를 280 * 280 * 3 이내의 크기를 설정하여 로딩하시오.\n","            * array로 변환 (keras.utils.img_to_array, np.expand_dims)\n","        * 데이터셋에 추가합니다.(데이터셋도 array)"],"metadata":{"id":"kAmc1-IfybNQ"}},{"cell_type":"markdown","source":["#### 1) 이미지 목록 만들기\n","* train, validation, test 폴더로 부터 이미지 목록을 생성합니다."],"metadata":{"id":"VztxNBlgygUm"}},{"cell_type":"code","source":["# 이미지 목록 저장\n","img_train_list = os.listdir(dataset_path+'copy_images/trainset/')\n","img_valid_list = os.listdir(dataset_path+'copy_images/validset/')\n","img_test_list = os.listdir(dataset_path+'copy_images/testset/')"],"metadata":{"id":"DN7vKW2Mwma8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 이미지들을 배열 데이터셋으로 만들기"],"metadata":{"id":"v2wCzaGSyjLK"}},{"cell_type":"code","source":["copy_train_path = dataset_path+'copy_images/trainset/'\n","copy_val_path = dataset_path+'copy_images/validset/'\n","copy_test_path = dataset_path+'copy_images/testset/'\n","\n","# 메모리, 처리시간을 위해서 이미지 크기 조정\n","img_size = 280 ## 사이즈 조정 가능"],"metadata":{"id":"FL8DnlKcyHva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x = []\n","val_x = []\n","test_x = []\n","\n","for imgname in img_train_list:\n","    img = keras.utils.load_img(copy_train_path + imgname, color_mode='grayscale', target_size=(img_size, img_size))  # 이미지 로딩\n","    img = keras.utils.img_to_array(img)\n","    train_x.append(img)\n","\n","for imgname in img_valid_list:\n","    img = keras.utils.load_img(copy_val_path + imgname, color_mode='grayscale', target_size=(img_size, img_size))  # 이미지 로딩\n","    img = keras.utils.img_to_array(img)\n","    val_x.append(img)\n","\n","for imgname in img_test_list:\n","    img = keras.utils.load_img(copy_test_path + imgname, color_mode='grayscale', target_size=(img_size, img_size))  # 이미지 로딩\n","    img = keras.utils.img_to_array(img)\n","    test_x.append(img)\n","\n","train_x = np.array(train_x)\n","val_x = np.array(val_x)\n","test_x = np.array(test_x)\n","\n","print(type(train_x), len(train_x), train_x.shape)\n","print(type(val_x), len(val_x), val_x.shape)\n","print(type(test_x), len(test_x), test_x.shape)"],"metadata":{"id":"D_LyWx3Gyn0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# min-max scaling\n","max_v, min_v = train_x.max(), train_x.min()\n","\n","train_x = (train_x - min_v) / (max_v - min_v)\n","val_x = (val_x - min_v) / (max_v - min_v)\n","test_x = (test_x - min_v) / (max_v - min_v)\n","\n","print('max :', train_x.max(),'  min :', train_x.min())"],"metadata":{"id":"4j3LrRZJy5Hw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (2) y : 클래스 만들기\n","- **세부요구사항**\n","    - Training set / Validation set / Test set의 y를 생성합니다.\n","        - 각각 normal, abnormal 데이터의 갯수를 다시 확인하고\n","        - normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"fq8pButHy6i_"}},{"cell_type":"code","source":["# 데이터 갯수 확인\n","print( len(img_train_list) )\n","print( len([val for val in img_train_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_valid_list) )\n","print( len([val for val in img_valid_list if val.startswith('ab_')]) )\n","print('---')\n","print( len(img_test_list) )\n","print( len([val for val in img_test_list if val.startswith('ab_')]) )"],"metadata":{"id":"4YDv__Jly7EM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* y_train, y_valid, y_test 만들기\n","    * normal, abnormal 데이터의 갯수를 다시 확인하고 normal을 0, abnormal을 1로 지정합니다."],"metadata":{"id":"TYObpC7GzK_H"}},{"cell_type":"code","source":["train_y = []\n","val_y = []\n","test_y = []\n","\n","for imgname in img_train_list:\n","    if imgname.startswith('ab_') == True:\n","        train_y.append(1)\n","    else:\n","        train_y.append(0)\n","    \n","for imgname in img_valid_list:\n","    if imgname.startswith('ab_') == True:\n","        val_y.append(1)\n","    else:\n","        val_y.append(0)\n","\n","for imgname in img_test_list:\n","    if imgname.startswith('ab_') == True:\n","        test_y.append(1)\n","    else:\n","        test_y.append(0)"],"metadata":{"id":"fCNKiM2_zAyV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y = np.array(train_y)\n","val_y = np.array(val_y)\n","test_y = np.array(test_y)\n","\n","print(train_y.shape, val_y.shape, test_y.shape)"],"metadata":{"id":"co6mYnFhzEPq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (3) 모델1\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 validation_data로 validation set을 사용하시오.\n","    - 반드시 Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."],"metadata":{"id":"XHoMlGAgy-Ei"}},{"cell_type":"markdown","source":["#### 1) 구조 설계"],"metadata":{"id":"6Pfj5tiLzhBW"}},{"cell_type":"code","source":["train_x.shape, train_y.shape"],"metadata":{"id":"cklvjAVzzYf7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 1. 세션 클리어\n","keras.backend.clear_session()\n","\n","# 2. 모델 선언\n","model = keras.models.Sequential()\n","\n","# 3. 모델 블록 조립\n","model.add(keras.layers.Input(shape=(280, 280, 1)))\n","\n","model.add(keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(keras.layers.Dropout(0.35))\n","\n","model.add(keras.layers.Flatten())\n","model.add(keras.layers.Dense(128, activation='relu'))\n","model.add(keras.layers.BatchNormalization())\n","model.add(keras.layers.Dense(1, activation='sigmoid'))\n","\n","# 4. 컴파일\n","model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')\n","model.summary()"],"metadata":{"id":"OZblkVvMza4H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 학습\n","* EarlyStopping 설정하고 학습시키기"],"metadata":{"id":"88O7M0c8zhpF"}},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping\n","\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)"],"metadata":{"id":"iFzn_WXKzjp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist = model.fit(train_x, train_y,\n","                 validation_data=(val_x, val_y),\n","                 batch_size=64,\n","                 epochs=10000,\n","                 callbacks=[es],\n","                 verbose=1)"],"metadata":{"id":"8KnmeD1Dzk8v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) test set으로 예측하고 평가하기\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"_0VhGujeznM1"}},{"cell_type":"code","source":["pred = model.predict(test_x)\n","y_pred = np.where(pred > 0.5, 1, 0)\n","\n","print(confusion_matrix(test_y, y_pred))\n","print(classification_report(test_y, y_pred))"],"metadata":{"id":"X56sCzzEzoXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if not isinstance(hist, dict):\n","    hist = hist.history\n","\n","plt.subplot(1, 2, 1) \n","plt.plot(hist['accuracy'])\n","plt.plot(hist['val_accuracy'])\n","plt.title('Accuracy : Training vs Validation')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc=0)\n","\n","plt.subplot(1, 2, 2) \n","plt.plot(hist['loss'])\n","plt.plot(hist['val_loss'])\n","plt.title('Loss : Training vs Validation')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Training', 'Validation'], loc=0)\n","\n","plt.show()"],"metadata":{"id":"gm_5YlTjzw_2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.모델링 II\n","* **세부요구사항**\n","    - 성능을 높이기 위해서 다음의 두가지를 시도해 봅시다.\n","        - Data Augmentation을 통해 데이터를 증가 시킵니다.\n","            - ImageDataGenerator를 사용합니다.\n","        - 사전 학습된 모델(Transfer Learning)을 가져다 사용해 봅시다.\n","            - VGG16(이미지넷)을 사용해 봅시다."],"metadata":{"id":"ee2ueBuk0O51"}},{"cell_type":"markdown","source":["### (1) Data Augmentation\n","- **세부요구사항**\n","    * 모델 학습에 이용할 이미지 데이터를 증강시키세요.\n","    * Keras의 ImageDataGenerator를 이용\n","        - [ImageDataGenerator document](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n","\n","    * image generator를 이용하여 학습\n","        * 모델 구조는 이미 생성한 1,2,3 중 하나를 선택하여 학습\n"],"metadata":{"id":"qJc6dv7v0QRP"}},{"cell_type":"code","source":["train_path = dataset_path+'Car_Images_train/'\n","valid_path = dataset_path+'Car_Images_val/'\n","test_path = dataset_path+'Car_Images_test/'"],"metadata":{"id":"SsKY-Vg40WEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1) ImageGenerator 생성\n","* ImageDataGenerator 함수 사용\n","    * 주요 옵션\n","        * rotation_range: 무작위 회전을 적용할 각도 범위\n","        * zoom_range: 무작위 줌을 적용할 범위 [1-zoom_range, 1+zoom_range]\n","        * horizontal_flip: 무작위 좌우반전을 적용할지 여부\n","        * vertical_flip: 무작위 상하반전을 적용할지 여부\n","        * rescale: 텐서의 모든 값을 rescale 값으로 나누어줌 (이 경우에는 255로 나누어서 0~1사이의 값으로 변경)"],"metadata":{"id":"DpwFkDyD0Y2M"}},{"cell_type":"code","source":["train_datagen = ImageDataGenerator(\n","                    rotation_range=30,      \n","                    zoom_range = 0.3,       \n","                    width_shift_range=0.1,  \n","                    height_shift_range=0.1, \n","                    horizontal_flip=True,   \n","                    vertical_flip=True,\n","                    rescale=1./255)     \n","\n","valid_datagen = ImageDataGenerator(\n","                    rotation_range=30,      \n","                    zoom_range = 0.3,       \n","                    width_shift_range=0.1,  \n","                    height_shift_range=0.1, \n","                    horizontal_flip=True,   \n","                    vertical_flip=True,\n","                    rescale=1./255)  "],"metadata":{"id":"dAoJXAbO0aN5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) 경로로 부터 이미지 불러 올 준비\n","* .flow_from_directory 이용\n","    * 디렉토리에서 이미지를 가져와서 데이터 증강을 적용하고 batch 단위로 제공하는 generator를 생성합니다.\n","    * 이미지를 불러올 때 target_size로 크기를 맞추고, \n","    * class_mode로 이진 분류(binary)를 수행하도록 지정합니다.\n"],"metadata":{"id":"eaGeX4od0bgc"}},{"cell_type":"code","source":["train_generator = train_datagen.flow_from_directory(train_path, \n","                                                    target_size=(280, 280),\n","                                                    class_mode='binary',\n","                                                    batch_size=128,\n","                                                    shuffle=True)\n","\n","valid_generator = valid_datagen.flow_from_directory(valid_path, \n","                                                    target_size=(280, 280),\n","                                                    class_mode='binary',\n","                                                    batch_size=128,\n","                                                    shuffle=True)"],"metadata":{"id":"xSBqL7RM0dAV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) 학습\n","- **세부요구사항**\n","    - Conv2D, MaxPooling2D, Flatten, Dense 레이어들을 이용하여 모델을 설계\n","    - 학습시 train_generator 이용. \n","    - validation_data = valid_generator 지정\n","    - Early Stopping 적용\n","    - 평가시, confusion matrix, accuracy, recall, precision, f1 score 등을 이용하시오."],"metadata":{"id":"EkaKgZo50epu"}},{"cell_type":"markdown","source":["* 구조 설계"],"metadata":{"id":"yLTjmJ1k0gUt"}},{"cell_type":"code","source":["keras.backend.clear_session()\n","\n","il = keras.layers.Input(shape=(280, 280, 3))\n","hl = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(il)\n","hl = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(hl)\n","hl = keras.layers.Conv2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(hl)\n","hl = keras.layers.BatchNormalization()(hl)\n","hl = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n","\n","hl = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(hl)\n","hl = keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(hl)\n","hl = keras.layers.BatchNormalization()(hl)\n","hl = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n","\n","hl = keras.layers.Conv2D(filters=128, kernel_size=(3, 3), padding='same', strides=(1, 1), activation='relu')(hl)\n","hl = keras.layers.BatchNormalization()(hl)\n","hl = keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2))(hl)\n","\n","hl = keras.layers.Flatten()(hl)\n","hl = keras.layers.Dense(256, activation='relu')(hl)\n","hl = keras.layers.Dense(256, activation='relu')(hl)\n","ol = keras.layers.Dense(1, activation='sigmoid')(hl)\n","\n","model_da1 = keras.models.Model(il, ol)\n","\n","model_da1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model_da1.summary()"],"metadata":{"id":"ADeEYNh20hvB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* 학습\n","    * EarlyStopping 설정하기\n","    * 학습 데이터에 train_generator, validation_data=valid_generator 사용"],"metadata":{"id":"x_vJurMy0jQN"}},{"cell_type":"code","source":["es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0,\n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)"],"metadata":{"id":"uhvhabXT0nhT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist_da1 = model_da1.fit(train_generator,\n","                         validation_data=valid_generator,\n","                         batch_size=64,\n","                         epochs=10000,\n","                         callbacks=[es],\n","                         verbose=1)"],"metadata":{"id":"lNCqJZS30nzX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가\n","* 평가는 confusion_matrix, classification_report 활용"],"metadata":{"id":"njtPzqOC0r5r"}},{"cell_type":"code","source":["pred_da1 = model_da1.predict(test_x)\n","y_pred_da1 = np.where(pred_da1 > 0.005, 1, 0)\n","\n","print(confusion_matrix(test_y, y_pred_da1))\n","print(classification_report(test_y, y_pred_da1))"],"metadata":{"id":"vdjAmd3Z0t23"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7ZsdfH4g0wsY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### (2) Transfer Learning\n","- **세부요구사항**\n","    * VGG16 모델은 1000개의 클래스를 분류하는 데 사용된 ImageNet 데이터셋을 기반으로 사전 학습된 가중치를 가지고 있습니다. \n","        * 따라서 이 모델은 이미지 분류 문제에 대한 높은 성능을 보입니다.\n","        * 이 모델은 보통 전이학습(transfer learning)에서 기본적으로 사용되며, 특히 대규모 데이터셋이 없을 때는 기본 모델로 사용되어 fine-tuning을 수행합니다.\n","    * VGG16 함수로 부터 base_model 저장\n"],"metadata":{"id":"eZh-MWR-0w8S"}},{"cell_type":"markdown","source":["#### 1) VGG16 불러와서 저장하기\n","* include_top=False로 설정하여 분류기를 제외하고 미리 학습된 가중치 imagenet을 로드합니다.\n","* .trainable을 True로 설정하여 모델의 모든 레이어들이 fine-tuning에 대해 업데이트되도록 합니다.\n"],"metadata":{"id":"3UtsKuUA037H"}},{"cell_type":"code","source":["keras.backend.clear_session()\n","\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(280, 280, 3))\n","base_model.trainable=True"],"metadata":{"id":"m72mKIkF0yWt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 2) VGG16과 연결한 구조 설계\n","* VGG16을 불러와서 Flatten, Dense 등으로 레이어 연결하기"],"metadata":{"id":"IyT38k4P05dB"}},{"cell_type":"code","source":["new_output = keras.layers.Flatten()(base_model.output)\n","new_output = keras.layers.Dense(128, activation='relu')(new_output)\n","new_output = keras.layers.Dense(1, activation='sigmoid')(new_output)\n","\n","model_tl1 = keras.models.Model(base_model.inputs, new_output)\n","model_tl1.summary()"],"metadata":{"id":"Vk79eGCn08F7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 3) 학습\n","- **세부요구사항**\n","    - 모델 학습 과정에 알맞은 보조 지표를 사용하세요.\n","    - 데이터\n","        * Image Generator를 연결하거나\n","        * 기존 train, validation 셋을 이용해도 됩니다.\n","        - Early Stopping을 반드시 사용하세요.\n","        - 최적의 가중치를 모델에 적용하세요."],"metadata":{"id":"isPOFyDO0-k-"}},{"cell_type":"code","source":["print(f'모델의 레이어 수 : {len(model_tl1.layers)}')"],"metadata":{"id":"4wTbpoyw0_75"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for idx, layer in enumerate(model_tl1.layers) :\n","    if idx < 17 :\n","        layer.trainable = False  # Frozen(기존 가중치 사용) 학습하지 않음\n","    else :\n","        layer.trainable = True  # layer weight 조절. 학습."],"metadata":{"id":"qnDID4Qk1Av5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_tl1.compile(loss='binary_crossentropy', metrics=['accuracy'],\n","             optimizer=keras.optimizers.Adam(learning_rate=0.001))"],"metadata":{"id":"6lDYxjvH1Asx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EarlyStopping\n","es = EarlyStopping(monitor='val_loss',\n","                   min_delta=0, \n","                   patience=5,\n","                   verbose=1,\n","                   restore_best_weights=True)"],"metadata":{"id":"STYoJKC51Aq2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hist_tl1 = model_tl1.fit(train_x, train_y,\n","                         validation_data=(val_x, val_y),\n","                         batch_size=128,\n","                         epochs=10000,\n","                         callbacks=[es],\n","                         verbose=1)"],"metadata":{"id":"ixRydpOs1Aor"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 4) 성능 평가"],"metadata":{"id":"RvpDX-ue1Hyf"}},{"cell_type":"code","source":["pred_tl1 = model_tl1.predict(test_x)\n","y_pred_tl1 = np.where(pred_tl1 > 0.5, 1, 0)\n","# y_pred_tl1 = pred_tl1.argmax(axis=1)\n","\n","print(confusion_matrix(test_y, y_pred_tl1))\n","print(classification_report(test_y, y_pred_tl1))"],"metadata":{"id":"pbnbnh-W1Amf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UW9vNs3v1APn"},"execution_count":null,"outputs":[]}]}